{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08e4a5fd-e831-4c99-9831-c437624deb7c",
   "metadata": {},
   "source": [
    "# MAPD-B distributed processing exam\n",
    "## Project 4: Streaming processing of cosmic rays using Drift Tubes detectors\n",
    "\n",
    "The goal of this project is to reproduce a real-time processing of real data collected in a\n",
    "particle physics detector and publish the results in a dashboard for live monitoring.\n",
    "\n",
    "### Students:\n",
    "* [Hilario Capettini](https://github.com/hcapettini2) (2013031)\n",
    "* [Javier Gerardo Carmona](https://github.com/eigen-carmona/) (2005005)\n",
    "* [Saverio Monaco](https://github.com/SaverioMonaco/) (2012264)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1d6a4-bc7a-4b1e-9546-025bd82e99a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95ec7da7-a558-4f5e-a1fc-d9945961d55b",
   "metadata": {},
   "source": [
    "##  The Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59b6931-a589-4a7b-a7e7-c9bed271219e",
   "metadata": {},
   "source": [
    "5 Cloud Veneto VMs were assigned for this project:\n",
    "* MAPD-B_Gr17-5 10.67.22.83\n",
    "* MAPD-B_Gr17-4 10.67.22.136\n",
    "* MAPD-B_Gr17-3 10.67.22.102\n",
    "* MAPD-B_Gr17-2 10.67.22.39\n",
    "* MAPD-B_Gr17-1 10.67.22.137\n",
    "\n",
    "Each machine runs CentOs and the Specs are:\n",
    "* RAM:   8GB\n",
    "* VCPUs: 4\n",
    "* Disk:  25GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba620d1-035c-421a-aa4a-9c53d406d5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47b91af5-1fad-48fb-8c7d-00e847362d5b",
   "metadata": {},
   "source": [
    "## Setting the Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79d48f2-1f15-423f-a6e5-66d981be5222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe here we can spend a few words on how to set up a Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9584302e-f791-4e82-863f-63d73369d089",
   "metadata": {},
   "source": [
    "### Configuration chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b623db46-4897-484c-b604-4fecdd35d19c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c063a4c7-98f7-4de1-8121-5756c0144096",
   "metadata": {},
   "source": [
    "### Benchmarks of other configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bd9b806-cdbe-42a2-8553-e77754b31a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we basically justify why we chosen the current configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790f8e0d-9da7-4101-bfcd-d0b8308756af",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setting Kafka and Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5340252-02e2-40f4-9014-ef5c1b84a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe here we can spend a few words about the commands on how to create the pipeline,\n",
    "# in a cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e759db4c-d7fb-41c2-b607-e590eb6493aa",
   "metadata": {},
   "source": [
    "### Consumer and Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4219c36c-6b11-4a81-9863-31e71d56ae2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc7031d1-0161-4c97-80d5-6687be15b325",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8742d0c-e109-4c25-993c-371af7149825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- HEAD: integer (nullable = true)\n",
      " |-- FPGA: integer (nullable = true)\n",
      " |-- TDC_CHANNEL: integer (nullable = true)\n",
      " |-- ORBIT_CNT: double (nullable = true)\n",
      " |-- BX_COUNTER: integer (nullable = true)\n",
      " |-- TDC_MEAS: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flatDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82cb553-6cd6-46b1-b0fa-5a8dcf8d83fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Colection of functions for the main computation\n",
    "\n",
    "def chamber_assignment(df):\n",
    "    '''Assign chamber number and leave the scintillator carriers with chamber == null'''\n",
    "    \n",
    "    return(df.withColumn('CHAMBER',when(col(\"FPGA\") == 0, \n",
    "                                                when(col(\"TDC_CHANNEL\")<=63,1).\\\n",
    "                                                otherwise(when(col(\"TDC_CHANNEL\")<128,2))).\\\n",
    "                                           otherwise(when(col(\"TDC_CHANNEL\")<=63,3).\\\n",
    "                                                     otherwise(when(col(\"TDC_CHANNEL\")<128,4))\n",
    "                                           )).\\\n",
    "                                           select([ col('TDC_CHANNEL'), col('ORBIT_CNT'),\n",
    "                                           col('BX_COUNTER'),col('TDC_MEAS'),\n",
    "                                           col('CHAMBER')])\n",
    "          )\n",
    "\n",
    "def scintillator_data(df):\n",
    "    '''Define a dataframe containing the relevant information for \n",
    "    the scintillator analysis''' \n",
    "    \n",
    "    #First we filter the events encoding the passage time,\n",
    "    #then we add the PASSAGE time for each event \n",
    "    #Finally if we have two scilantor hits within the same orbit we keep \n",
    "    #the one with the smaller time\n",
    "    return(df.filter((col(\"CHAMBER\").isNull())).\\\n",
    "                          withColumn(\"PASSAGETIME\", 25 * (col(\"ORBIT_CNT\") * 3564 + col(\"BX_COUNTER\") + col(\"TDC_MEAS\")/30)).\\\n",
    "                          drop(\"TDC_CHANNEL\").drop(\"BX_COUNTER\").\\\n",
    "                          drop(\"TDC_MEAS\").drop(\"CHAMBER\").\\\n",
    "                          groupBy(\"ORBIT_CNT\").min(\"PASSAGETIME\").\\\n",
    "                          withColumnRenamed(\"ORBIT_CNT\",\"ORBIT_CNT_sci\").\\\n",
    "                          withColumnRenamed(\"min(PASSAGETIME)\",\"PASSAGETIME\")\n",
    "          )\n",
    "\n",
    "\n",
    "def histogram_1(df,min_v_1,max_v_1,inc_1):\n",
    "    '''This function return the bins and counts for the first requested histogram'''\n",
    "    hist_1_bins = np.arange(min_v_1,max_v_1,inc_1)\n",
    "    hist_1 = df\\\n",
    "        .filter((min_v_1<=F.col('TDC_CHANNEL')) & (F.col('TDC_CHANNEL')<=max_v_1))\\\n",
    "        .withColumn('BIN', F.floor((F.col('TDC_CHANNEL')-min_v_1)/inc_1))\\\n",
    "        .groupBy('CHAMBER','BIN')\\\n",
    "        .count().select('CHAMBER','BIN', col('count').alias('COUNT'))\n",
    "    return (hist_1_bins, hist_1)\n",
    "    \n",
    "\n",
    "def histogram_2(df,min_v_2,max_v_2,inc_2):\n",
    "    '''This function return the bins and counts for the second requested histogram'''\n",
    "    hist_2_bins = np.arange(min_v_2,max_v_2,inc_2)\n",
    "    hist_2 = df\\\n",
    "        .groupBy('CHAMBER','ORBIT_CNT')\\\n",
    "        .agg(F.countDistinct('TDC_CHANNEL').alias('ACTIVE_CHANNELS'))\\\n",
    "        .filter((min_v_2<=F.col('ORBIT_CNT'))&(F.col('ORBIT_CNT')<=max_v_2))\\\n",
    "        .withColumn('BIN',F.floor((F.col('ORBIT_CNT')-min_v_2)/inc_2))\\\n",
    "        .groupBy('CHAMBER','BIN')\\\n",
    "        .agg(F.sum('ACTIVE_CHANNELS').alias('COUNT'))#.collect()\n",
    "    return(hist_2_bins, hist_2)\n",
    "\n",
    "def histogram_3(df,min_v_3,max_v_3,inc_3):\n",
    "    '''This function return the bins and counts for the third requested histogram'''\n",
    "    hist_3_bins = np.arange(min_v_3,max_v_3,inc_3)\n",
    "    hist_3 = df\\\n",
    "        .filter((min_v_3<=F.col('TDC_CHANNEL')) & (F.col('TDC_CHANNEL')<=max_v_3))\\\n",
    "        .withColumn('BIN', F.floor((F.col('TDC_CHANNEL')-min_v_3)/inc_3))\\\n",
    "        .groupBy('CHAMBER','BIN')\\\n",
    "        .count().select('CHAMBER','BIN', col('count').alias('COUNT')) \n",
    "    return(hist_3_bins, hist_3)\n",
    "\n",
    "def histogram_4(df,min_v_4,max_v_4,inc_4):\n",
    "    '''This function return the bins and counts for the fourth requested histogram'''\n",
    "    hist_4_bins = np.arange(min_v_4,max_v_4,inc_4)\n",
    "    hist_4 = df\\\n",
    "        .filter((min_v_4<=F.col('DRIFTIME')) & (F.col('DRIFTIME')<=max_v_4))\\\n",
    "        .withColumn('BIN', F.floor((F.col('DRIFTIME')-min_v_4)/inc_4))\\\n",
    "        .groupBy('CHAMBER','BIN')\\\n",
    "        .count().select('CHAMBER','BIN', col('count').alias('COUNT')) \n",
    "    return(hist_4_bins, hist_4)\n",
    "\n",
    "\n",
    "   \n",
    "def numpify(bins, pos_count):\n",
    "    '''NUMPIFY RESULTS'''\n",
    "    counter = np.zeros(len(bins))#np.zeros(len(bins)-1)?\n",
    "    positions = np.array(list(pos_count.keys()))\n",
    "    counts = np.array(list(pos_count.values()))\n",
    "    counter[positions] = counts\n",
    "    return counter\n",
    "\n",
    "\n",
    "def prepare_results(chamber_hits,hist_1,hist_2,hist_3,hist_4,hist_1_bins,hist_2_bins,hist_3_bins,hist_4_bins):\n",
    "    '''COLLECTING RESULTS'''\n",
    "    _chamber_hits = chamber_hits.collect()\n",
    "    \n",
    "    _hist_1 = hist_1.groupBy('CHAMBER').agg(\n",
    "    F.map_from_entries(\n",
    "        F.collect_list(\n",
    "            F.struct(\"BIN\", \"COUNT\"))).alias(\"COUNT\")\n",
    "        ).collect()\n",
    "\n",
    "    _hist_2 = hist_2.groupBy('CHAMBER').agg(\n",
    "    F.map_from_entries(\n",
    "        F.collect_list(\n",
    "            F.struct(\"BIN\",\"COUNT\"))).alias(\"COUNT\")\n",
    "        ).collect()\n",
    "\n",
    "    _hist_3 = hist_3.groupBy('CHAMBER').agg(\n",
    "    F.map_from_entries(\n",
    "        F.collect_list(\n",
    "            F.struct(\"BIN\", \"COUNT\"))).alias(\"COUNT\")\n",
    "        ).collect()\n",
    "    \n",
    "    _hist_4 = hist_4.groupBy('CHAMBER').agg(\n",
    "    F.map_from_entries(\n",
    "        F.collect_list(\n",
    "            F.struct(\"BIN\", \"COUNT\"))).alias(\"COUNT\")\n",
    "        ).collect()\n",
    "    \n",
    "\n",
    "    # JSON FORMATING OF RESULTS\n",
    "    _hist_1_dict = {row.CHAMBER: {\n",
    "        'Bins': list(hist_1_bins), 'Counts': list(numpify(hist_1_bins,row.COUNT))\n",
    "    } for row in _hist_1}\n",
    "\n",
    "    _hist_2_dict = {row.CHAMBER: {\n",
    "        'Bins': list(hist_2_bins), 'Counts': list(numpify(hist_2_bins,row.COUNT))\n",
    "    } for row in _hist_2}\n",
    "    \n",
    "    _hist_3_dict = {row.CHAMBER: {\n",
    "        'Bins': list(hist_3_bins), 'Counts': list(numpify(hist_3_bins,row.COUNT))\n",
    "    } for row in _hist_3}\n",
    "        \n",
    "    _hist_4_dict = {row.CHAMBER: {\n",
    "        'Bins': list(hist_4_bins), 'Counts': list(numpify(hist_4_bins,row.COUNT))\n",
    "    } for row in _hist_4}\n",
    "    \n",
    "    return(_chamber_hits,_hist_1_dict,_hist_2_dict,_hist_3_dict,_hist_4_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce56de-aa4b-4a90-a951-9037f508d73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computations(df, epoch):\n",
    "    '''This is the main function of the code, it requires a dataframe as input. The dataframe is analysed\n",
    "       and the results are published in the kafka topic \"results\" '''\n",
    "    \n",
    "    #start=time.time()\n",
    "    main_df = chamber_assignment(df)\n",
    "\n",
    "    scintillator_df = scintillator_data(main_df)\n",
    "    \n",
    "    #Drop the columns with null values from main_df\n",
    "    hit_df = main_df.na.drop(subset=[\"CHAMBER\"])#.show()\n",
    "    \n",
    "    ## TOTAL NUMBER OF PROCESSED HITS\n",
    "    total_hits = hit_df.count()\n",
    "    if not total_hits: return\n",
    "\n",
    "    ## TOTAL NUMBER OF PROCESSED HITS PER CHAMBER\n",
    "    chamber_hits = hit_df\\\n",
    "        .groupBy('CHAMBER').count()\\\n",
    "        .select(col('CHAMBER'),col('count').alias('COUNT'))#.collect()\n",
    "    \n",
    "    ## ACTIVE TDC_CHANNEL PER CHAMBER\n",
    "    min_v_1 = 0\n",
    "    max_v_1 = 170\n",
    "    inc_1 = 5\n",
    "    hist_1_bins, hist_1 = histogram_1(hit_df,min_v_1,max_v_1,inc_1)\n",
    "    \n",
    "    ## ACTIVE TDC_CHANNEL PER CHAMBER PER ORBIT_CNT\n",
    "    min_v_2 = 6.e5 #main_df.agg(F.min(F.col('ORBIT_CNT')).alias('min')).collect()[-1].min\n",
    "    max_v_2 = 1.e7 #main_df.agg(F.max(F.col('ORBIT_CNT')).alias('max')).collect()[-1].max\n",
    "    inc_2 = 0.5e6\n",
    "    hist_2_bins, hist_2 = histogram_2(hit_df,min_v_2,max_v_2,inc_2)\n",
    "    \n",
    "    \n",
    "    #keep only the hits with a scintillator signal within the same orbit\n",
    "    chamber_sci = hit_df.join(scintillator_df,main_df.ORBIT_CNT ==  scintillator_df.ORBIT_CNT_sci,\"inner\")\n",
    "\n",
    "    ## ADD TIME CORRECTION BY CHAMBER\n",
    "    chamber_sci = chamber_sci.withColumn('TIME_OFFSET',when(col(\"CHAMBER\") == 1, 93.9).\\\n",
    "                                                       when(col(\"CHAMBER\") == 2, 101.4).\\\n",
    "                                                       when(col(\"CHAMBER\") == 3, 95.5).\\\n",
    "                                                       when(col(\"CHAMBER\") == 4, 92.4))\n",
    "\n",
    "    #Add the ABSSOLUTETIME and DRIFTIME\n",
    "    chamber_sci = chamber_sci.withColumn(\"ABSOLUTETIME\",\n",
    "                             25 * (col(\"ORBIT_CNT\") * 3564 + col(\"BX_COUNTER\") + col(\"TDC_MEAS\")/30)).\\\n",
    "                              withColumn(\"DRIFTIME\",col(\"ABSOLUTETIME\")-col(\"PASSAGETIME\") + col(\"TIME_OFFSET\"))\n",
    "   \n",
    "\n",
    "    ## ACTIVE TDC_CHANNEL PER CHAMBER WITHIN SCINTILLATOR SIGNAL\n",
    "    min_v_3 = 0\n",
    "    max_v_3= 170\n",
    "    inc_3 = 5\n",
    "    hist_3_bins, hist_3 = histogram_3(chamber_sci,min_v_3,max_v_3,inc_3)\n",
    "    \n",
    "\n",
    "    ## HISTOGRAM OF DRIFTIME, PER CHAMBER\n",
    "    min_v_4 = 0\n",
    "    max_v_4= 1000\n",
    "    inc_4 = 10\n",
    "    hist_4_bins, hist_4 = histogram_4(chamber_sci,min_v_4,max_v_4,inc_4)\n",
    "    \n",
    "    #PREPARE THE RESULTS\n",
    "    _chamber_hits,_hist_1_dict,_hist_2_dict,_hist_3_dict,_hist_4_dict = prepare_results(chamber_hits,hist_1,hist_2,hist_3,hist_4,hist_1_bins,hist_2_bins,hist_3_bins,hist_4_bins)\n",
    "    \n",
    "    \n",
    "    results = {f'Chamber_{row.CHAMBER}': {\n",
    "        'Count': int(row.COUNT),\n",
    "        'Hist_1': _hist_1_dict.get(row.CHAMBER, {'Bins': list(np.arange(min_v_1,max_v_1,inc_1)), 'Counts' : [0]*(len(list(np.arange(min_v_1,max_v_1,inc_1)))-1)}),\n",
    "        'Hist_2': _hist_2_dict.get(row.CHAMBER, {'Bins': list(np.arange(min_v_2,max_v_2,inc_2)), 'Counts' : [0]*(len(list(np.arange(min_v_2,max_v_2,inc_2)))-1)}),\n",
    "        'Hist_3': _hist_3_dict.get(row.CHAMBER, {'Bins': list(np.arange(min_v_3,max_v_3,inc_3)), 'Counts' : [0]*(len(list(np.arange(min_v_3,max_v_3,inc_3)))-1)}),\n",
    "        'Hist_4': _hist_4_dict.get(row.CHAMBER, {'Bins': list(np.arange(min_v_4,max_v_4,inc_4)), 'Counts' : [0]*(len(list(np.arange(min_v_4,max_v_4,inc_4)))-1)})} for row in _chamber_hits}\n",
    "\n",
    "    results.update({\n",
    "        'Index': time.time(),\n",
    "        'Total Count': int(total_hits)\n",
    "    })\n",
    "\n",
    "    producer.send(topic=\"results\", value= str(results).encode('utf-8'))\n",
    "    #producer.flush()\n",
    "    end = time.time()\n",
    "\n",
    "    print(\"Time =\",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f359ee29-635c-4254-9e8c-083941d0a0af",
   "metadata": {},
   "source": [
    "##  Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76d24e6-33bd-4f4d-852e-e0074330b15f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af20a4c7-ac1a-4c42-89ea-4e9ad33f064b",
   "metadata": {},
   "source": [
    "### Vertical scalability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af05e7-bdf7-4521-a4d8-7055299a18d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cba300f-084f-40c4-a19b-728e18149692",
   "metadata": {},
   "source": [
    "### Horizontal scalability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50bec69-2fca-4f35-99aa-f7f2f9255728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f3d403d-b185-48c9-9200-1b354f06760d",
   "metadata": {},
   "source": [
    "### Scaling with ammount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b7a81-15dd-456b-825e-6da0f3196c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e67acc34-cc99-401e-856f-e2ded07c16ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Live Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c8c4c4-5482-4317-bad5-f335624af5be",
   "metadata": {},
   "source": [
    "To create a live webpage dashboard we used [Plotly Dash](https://github.com/plotly/dash) a Python library built on top of Plotly to create Analytical Web Apps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7f4f8a-623f-43e3-9e0b-f61afc87a34f",
   "metadata": {},
   "source": [
    "The information reported in the Dashboard are the following:\n",
    "\n",
    "**PLOTS**\n",
    "1. total number of processed hits, post-clensing (PLOT AND TABLE)\n",
    "2. total number of processed hits, post-clensing, per chamber (TABLE)\n",
    "3. histogram of the counts of active TDC_CHANNEL, per chamber (HISTOGRAM 1)\n",
    "4. histogram of the total number of active TDC_CHANNEL in each ORBIT_CNT, per chamber (HISTOGRAM 2)\n",
    "\n",
    "**EXTRA**\n",
    "1. histogram of the counts of active TDC_CHANNEL, per chamber, ONLY for those orbits with at least one scintillator signal in it (EXTRA 1)\n",
    "2. histogram of the DRIFTIME, per chamber (EXTRA 2 AND EXTRA 2 (cumulative))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b036b401-1cd5-4dfd-9701-05c61279ef1a",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/dashboard.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb01c6-156e-4443-8e63-4529245813f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f40c076f-ef49-4d17-befe-e52a44276f21",
   "metadata": {},
   "source": [
    "## Backup Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92092f10-274a-442f-ba81-9eae2df1c9c1",
   "metadata": {},
   "source": [
    "### Data-cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3362049-76d4-4c45-a16e-09f66e5d13be",
   "metadata": {},
   "source": [
    "Data-cleansing : $$\\text{HEAD} == 2 $$\n",
    "Other entries provide ancillary information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cb8a7e-1162-4669-8671-30d2fd99d7ba",
   "metadata": {},
   "source": [
    "### Chamber mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaf37e5-fb71-4ce7-9701-a9ae1805eeeb",
   "metadata": {},
   "source": [
    "• Chamber 0 → (FPGA = 0) AND (TDC_CHANNEL in [0-63])\\\n",
    "• Chamber 1 → (FPGA = 0) AND (TDC_CHANNEL in [64-127])\\\n",
    "• Chamber 2 → (FPGA = 1) AND (TDC_CHANNEL in [0-63])\\\n",
    "• Chamber 3 → (FPGA = 1) AND (TDC_CHANNEL in [64-127])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4866553b-cf9b-41d9-b4fb-7eba64292fcb",
   "metadata": {},
   "source": [
    "### Driftime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882d1078-2650-4429-85ae-ddcfa3d2c2e6",
   "metadata": {},
   "source": [
    "#### Absolute time\n",
    "For each hit we can associate an absolute time:\n",
    "\n",
    "$$t_{TDC\\space hit} = 25 ∗ ( ORBIT\\_CNT ∗ 3564 + BX\\_COUNTER + TDC\\_MEAS /30)\\quad [ns]$$\n",
    "\n",
    "\n",
    "#### Passage of a muon time\n",
    "The passage time of any muon is provided by an external scintillator signal which correspond to the following selection:\n",
    "\n",
    "$$\\text{(FPGA == 1) AND (TDC_CHANNEL == 128)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff90b15e-cb32-43da-a142-f54f4c945f28",
   "metadata": {},
   "source": [
    "#### Scintillator time offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75fad315-c639-496a-8df2-743146f8e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scintillator time offset by Chamber\n",
    "time_offset_by_chamber = {\n",
    "0: 95.0 - 1.1, # Ch 0\n",
    "1: 95.0 + 6.4, # Ch 1\n",
    "2: 95.0 + 0.5, # Ch 2\n",
    "3: 95.0 - 2.6, # Ch 3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e15922c-bd41-4b9d-8c88-102223ccc4fa",
   "metadata": {},
   "source": [
    "#### Driftime\n",
    "For those hits with a scintillator signal within the same orbit, a DRIFTIME can be defined, corresponding to the ABSOLUTETIME difference between each hit and the scintillator (from the same orbit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f57953f-479e-4098-a1c9-03d1db755ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
